{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Imports & Setup:**\n",
    "---------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import gc\n",
    "import os\n",
    "import time\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "from torch.utils.data import *\n",
    "from torchvision import models\n",
    "from torch import nn\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.modules.distance import PairwiseDistance\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed\n",
    "torch.manual_seed(0)\n",
    "# Set device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create dataframe:**\n",
    "-------------\n",
    "* Combine all mask to obtain a single entry per image containing all the masks\n",
    "* **Assign a class based on inverse frequency:** If an image contains the least frequent class, assign this class, continue with the second least frequent class...\n",
    "* Undersample the data based on least frequent class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('../input/severstal-steel-defect-detection/train.csv')\n",
    "train_df['ImageId'] = train_df['ImageId_ClassId'].apply(lambda x: x.split('_')[0])\n",
    "train_df['ClassId'] = train_df['ImageId_ClassId'].apply(lambda x: x.split('_')[1])\n",
    "\n",
    "encoded_pixels_class_1 = []\n",
    "encoded_pixels_class_2 = []\n",
    "encoded_pixels_class_3 = []\n",
    "encoded_pixels_class_4 = []\n",
    "train_df1 = train_df[train_df['ClassId']=='1']\n",
    "train_df2 = train_df[train_df['ClassId']=='2']\n",
    "train_df3 = train_df[train_df['ClassId']=='3']\n",
    "train_df4 = train_df[train_df['ClassId']=='4']\n",
    "for image in set(train_df1['ImageId'].values.tolist()):\n",
    "    encoded_pixels_class_1.append(train_df1[train_df1['ImageId']==image]['EncodedPixels'].values.tolist())\n",
    "for image in set(train_df2['ImageId'].values.tolist()):\n",
    "    encoded_pixels_class_2.append(train_df2[train_df2['ImageId']==image]['EncodedPixels'].values.tolist())\n",
    "for image in set(train_df3['ImageId'].values.tolist()):\n",
    "    encoded_pixels_class_3.append(train_df3[train_df3['ImageId']==image]['EncodedPixels'].values.tolist())\n",
    "for image in set(train_df4['ImageId'].values.tolist()):\n",
    "    encoded_pixels_class_4.append(train_df4[train_df4['ImageId']==image]['EncodedPixels'].values.tolist())\n",
    "    \n",
    "unique_images = list(set(train_df['ImageId'].values.tolist()))\n",
    "data = {'ImageId': unique_images,\n",
    "        'EP1': [item for sublist in encoded_pixels_class_1 for item in sublist],\n",
    "        'EP2': [item for sublist in encoded_pixels_class_2 for item in sublist],\n",
    "        'EP3': [item for sublist in encoded_pixels_class_3 for item in sublist],\n",
    "        'EP4': [item for sublist in encoded_pixels_class_4 for item in sublist]}\n",
    "train_df2 = pd.DataFrame(data)\n",
    "print(train_df2.shape)\n",
    "train_df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_frquencies = [\n",
    "    abs(len(train_df2[train_df2['EP1'].isna()])-len(train_df2)),\n",
    "    abs(len(train_df2[train_df2['EP2'].isna()])-len(train_df2)),\n",
    "    abs(len(train_df2[train_df2['EP3'].isna()])-len(train_df2)),\n",
    "    abs(len(train_df2[train_df2['EP4'].isna()])-len(train_df2))\n",
    "]\n",
    "\n",
    "classes = []\n",
    "for i, row in train_df2.iterrows():\n",
    "    if type(row['EP2']) != float:\n",
    "        classes.append(2)\n",
    "    elif type(row['EP4']) != float:\n",
    "        classes.append(4)\n",
    "    elif type(row['EP1']) != float:\n",
    "        classes.append(1)\n",
    "    elif type(row['EP3']) != float:\n",
    "        classes.append(3)\n",
    "    else:\n",
    "        classes.append(0)\n",
    "\n",
    "train_df2['class'] = classes\n",
    "print(train_df2.shape)\n",
    "train_df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print('Class count before:\\n'+str(train_df2['class'].value_counts()))\n",
    "\n",
    "# Separate majority and minority classes\n",
    "#train_df2_class1 = train_df2[train_df2['class']==1]\n",
    "#train_df2_class2 = train_df2[train_df2['class']==2]\n",
    "#train_df2_class3 = train_df2[train_df2['class']==3]\n",
    "#train_df2_class4 = train_df2[train_df2['class']==4]\n",
    "#train_df2_class0 = train_df2[train_df2['class']==0]\n",
    "\n",
    "# Downsample majority class\n",
    "#train_df2_class1_downsampled = resample(train_df2_class1, replace=False, n_samples=min(class_frquencies), random_state=123)\n",
    "#train_df2_class3_downsampled = resample(train_df2_class3, replace=False, n_samples=min(class_frquencies), random_state=123)\n",
    "#train_df2_class4_downsampled = resample(train_df2_class4, replace=False, n_samples=min(class_frquencies), random_state=123)\n",
    "#train_df2_class0_downsampled = resample(train_df2_class0, replace=False, n_samples=min(class_frquencies), random_state=123)\n",
    "\n",
    "# Combine minority class with downsampled majority class\n",
    "#train_df2 = pd.concat([train_df2_class1_downsampled, train_df2_class2, train_df2_class3_downsampled, train_df2_class4_downsampled])\n",
    " \n",
    "#print('Class count after:\\n'+str(train_df2['class'].value_counts()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load data:**\n",
    "-------------------\n",
    "* helper methods\n",
    "* create dataset\n",
    "* visualize example images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask2rle(img):\n",
    "    '''\n",
    "    img: numpy array, 1 - mask, 0 - background\n",
    "    Returns run length as string formated\n",
    "    '''\n",
    "    pixels= img.T.flatten()\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)\n",
    "\n",
    "def rle2mask(rle, input_shape, label):\n",
    "    width, height = input_shape[:2]\n",
    "    \n",
    "    mask= np.zeros( width*height ).astype(np.uint8)\n",
    "    \n",
    "    array = np.asarray([int(x) for x in rle.split()])\n",
    "    starts = array[0::2]\n",
    "    lengths = array[1::2]\n",
    "\n",
    "    current_position = 0\n",
    "    for index, start in enumerate(starts):\n",
    "        mask[int(start):int(start+lengths[index])] = label\n",
    "        current_position += lengths[index]\n",
    "        \n",
    "    return mask.reshape(height, width).T\n",
    "\n",
    "def build_masks(rles, input_shape):\n",
    "    depth = len(rles)\n",
    "    masks = np.zeros(input_shape)\n",
    "    \n",
    "    for i, rle in enumerate(rles):\n",
    "        if type(rle) is str:\n",
    "            masks += rle2mask(rle, input_shape, i+1)\n",
    "    \n",
    "    return masks\n",
    "\n",
    "def build_rles(masks):\n",
    "    width, height, depth = masks.shape\n",
    "    \n",
    "    rles = [mask2rle(masks[:, :, i+1])\n",
    "            for i in range(depth-1)]\n",
    "    \n",
    "    return rles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_img(code, base, resize=True):\n",
    "    path = f'{base}/{code}'\n",
    "    img = cv2.imread(path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    if resize:\n",
    "        img = cv2.resize(img, (800, 128))\n",
    "    \n",
    "    return img\n",
    "\n",
    "def validate_path(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_path = '../tmp/train'\n",
    "train_path = '../input/severstal-steel-defect-detection/train_images'\n",
    "#validate_path(train_path)\n",
    "\n",
    "#for i, code in enumerate(tqdm(train_df2['ImageId'])):\n",
    "#    img = load_img(\n",
    "#        code,\n",
    "#        base='../input/severstal-steel-defect-detection/train_images'\n",
    "#    )\n",
    "#    path = code.replace('.jpg', '')\n",
    "#    cv2.imwrite(f'{train_path}/{path}.png', img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_df2['EP1'] = train_df2['EP1'].apply(\n",
    "#    lambda x: x if type(x) == float else mask2rle(cv2.resize(rle2mask(x, (256, 1600), 1), (800, 128), interpolation=cv2.INTER_NEAREST)) \n",
    "#)\n",
    "#train_df2['EP2'] = train_df2['EP2'].apply(\n",
    "#    lambda x: x if type(x) == float else mask2rle(cv2.resize(rle2mask(x, (256, 1600), 1), (800, 128), interpolation=cv2.INTER_NEAREST)) \n",
    "#)\n",
    "#train_df2['EP3'] = train_df2['EP3'].apply(\n",
    "#    lambda x: x if type(x) == float else mask2rle(cv2.resize(rle2mask(x, (256, 1600), 1), (800, 128), interpolation=cv2.INTER_NEAREST)) \n",
    "#)\n",
    "#train_df2['EP4'] = train_df2['EP4'].apply(\n",
    "#    lambda x: x if type(x) == float else mask2rle(cv2.resize(rle2mask(x, (256, 1600), 1), (800, 128), interpolation=cv2.INTER_NEAREST)) \n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_df2['ImageId'] = train_df2['ImageId'].apply(\n",
    "#    lambda x: x.replace('.jpg', '.png')\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SteelDataset(Dataset):\n",
    "    def __init__(self, df, x_col, y_cols, path):\n",
    "        self.df = df\n",
    "        self.x_col = x_col\n",
    "        self.y_cols = y_cols\n",
    "        self.path = path\n",
    "        self.mean = np.array([0.485, 0.456, 0.406])\n",
    "        self.std = np.array([0.229, 0.224, 0.225])\n",
    "        self.edge_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (7, 7))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # load image\n",
    "        im_name = self.df[self.x_col].iloc[idx]\n",
    "        img_path = f\"{self.path}/{im_name}\"\n",
    "        img = cv2.imread(img_path)\n",
    "   \n",
    "        # load mask\n",
    "        image_df = self.df[self.df[self.x_col] == im_name]\n",
    "        rles = [image_df['EP1'].values[0],image_df['EP2'].values[0],image_df['EP3'].values[0],image_df['EP4'].values[0]]\n",
    "        masks = build_masks(rles, (256, 1600)).astype(np.uint8)\n",
    "        #masks = np.expand_dims(masks, axis=-1)\n",
    "        \n",
    "        # create borders\n",
    "        rgb_masks = cv2.cvtColor(masks,cv2.COLOR_GRAY2RGB)\n",
    "        rgb_masks[np.where((rgb_masks==[1,1,1]).all(axis=2))] = [0,0,128]\n",
    "        rgb_masks[np.where((rgb_masks==[2,2,2]).all(axis=2))] = [0,128,0]\n",
    "        rgb_masks[np.where((rgb_masks==[3,3,3]).all(axis=2))] = [0,128,128]\n",
    "        rgb_masks[np.where((rgb_masks==[4,4,4]).all(axis=2))] = [128,0,0]\n",
    "        cgt = cv2.Canny(rgb_masks, 5, 5, apertureSize=7)\n",
    "        cgt = cv2.dilate(cgt, self.edge_kernel).astype(np.uint8)\n",
    "        cgt[cgt == 255] = 1\n",
    "        #cgt = np.expand_dims(cgt, axis=-1)\n",
    "        \n",
    "        # normalize image\n",
    "        img = img.astype(np.float32) / 255.0\n",
    "        img = img - self.mean\n",
    "        img = img / self.std\n",
    "        \n",
    "        # convert to torch tensors\n",
    "        img = torch.tensor(img)\n",
    "        img = img.permute(2, 0, 1)\n",
    "        masks = torch.tensor(masks)\n",
    "        masks = masks.permute(0, 1)\n",
    "        cgt = torch.tensor(cgt)\n",
    "        cgt = cgt.permute(0, 1)\n",
    "        \n",
    "        #combine\n",
    "        sample = {'image': img, 'masks': masks, 'cgt': cgt}\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steel_dataset = SteelDataset(train_df2, 'ImageId', ['EP1', 'EP2', 'EP3', 'EP4'], train_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inc = 0\n",
    "fig, axs = plt.subplots(15, figsize=(25, 25))\n",
    "for i in range(0,15,3):\n",
    "    axs[i].imshow(steel_dataset.__getitem__(i+inc)['image'].permute(1, 2, 0)[:,:,0], cmap='gray')\n",
    "    axs[i].axis('off')\n",
    "    axs[i+1].imshow(steel_dataset.__getitem__(i+inc)['masks'])\n",
    "    axs[i+1].axis('off')\n",
    "    axs[i+2].imshow(steel_dataset.__getitem__(i+inc)['cgt'])\n",
    "    axs[i+2].axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Metrics:**\n",
    "------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#according paper said , sigmoid better than softmax\n",
    "class SigmoidFocalLoss(nn.Module):\n",
    "    def __init__(self, ignore_label, gamma=2.0, alpha=0.25,\n",
    "                 reduction='mean'):\n",
    "        super(SigmoidFocalLoss, self).__init__()\n",
    "        self.ignore_label = ignore_label\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, pred, target):\n",
    "        b, h, w = target.size()\n",
    "        pred = pred.view(b, -1, 1)\n",
    "        pred_sigmoid = pred.sigmoid()\n",
    "        target = target.view(b, -1).float()\n",
    "        mask = (target.ne(self.ignore_label)).float()\n",
    "        target = mask * target\n",
    "        onehot = target.view(b, -1, 1)\n",
    "\n",
    "        pos_part = (1 - pred_sigmoid) ** self.gamma * torch.log(pred_sigmoid + 1e-4)\n",
    "        neg_part = pred_sigmoid ** self.gamma *  torch.log(1-pred_sigmoid+1e-4)\n",
    "\n",
    "        loss = -(self.alpha * pos_part*(onehot == 1).float() + (1 - self.alpha) * neg_part*(onehot==0).float()).sum(\n",
    "            dim=-1)*mask\n",
    "        if self.reduction == 'mean':\n",
    "            loss = loss.mean()\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# taken from https://www.kaggle.com/iafoss/unet34-dice-0-87\n",
    "def dice(pred, targs):\n",
    "    smooth = 1.0\n",
    "    dice = np.zeros(len(pred))\n",
    "    class_dice = [[] for i in range(len(pred))]\n",
    "    targs = torch.squeeze(targs)\n",
    "    masks_target = torch.from_numpy(np.stack([np.where(targs==label, 1, 0) for label in range(5)], axis=1))\n",
    "    \n",
    "    for i in range(len(pred)):\n",
    "        tmp_class_dice = np.zeros(5)\n",
    "        for j in range(5):\n",
    "            iflat = pred[i][j].view(-1).float()\n",
    "            tflat = masks_target[i][j].view(-1).float()\n",
    "            intersection = (iflat * tflat).sum()\n",
    "            tmp_class_dice[j] += (2.0 * intersection + smooth).item()/(iflat.sum() + tflat.sum() + smooth).item()\n",
    "        class_dice[i] = tmp_class_dice\n",
    "    class_dice = np.sum(class_dice, axis=0) / len(pred)\n",
    "    dice = np.mean(class_dice)\n",
    "    return np.round(class_dice,3), dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randint(0,5,(4,1,128,800))\n",
    "x2 = torch.from_numpy(np.stack([np.where(torch.squeeze(x)==label, 1, 0) for label in range(5)], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dice(x2,x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# taken from https://www.kaggle.com/iafoss/unet34-dice-0-87\n",
    "def IoU(pred, targs):\n",
    "    pred = (pred>0).double()\n",
    "    intersection = (pred*targs).sum()\n",
    "    return intersection / ((pred+targs).sum() - intersection + 1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create model:**\n",
    "-------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ResNet:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import math\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "\n",
    "\n",
    "__all__ = ['ResNet', 'resnet18', 'resnet34', 'resnet50', 'resnet101',\n",
    "           'resnet152']\n",
    "\n",
    "\n",
    "model_urls = {\n",
    "    'resnet18': 'https://download.pytorch.org/models/resnet18-5c106cde.pth',\n",
    "    'resnet34': 'https://download.pytorch.org/models/resnet34-333f7ec4.pth',\n",
    "    'resnet50': 'https://download.pytorch.org/models/resnet50-19c8e357.pth',\n",
    "    'resnet101': 'https://download.pytorch.org/models/resnet101-5d3b4d8f.pth',\n",
    "    'resnet152': 'https://download.pytorch.org/models/resnet152-b121ed2d.pth',\n",
    "}\n",
    "\n",
    "\n",
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    \"3x3 convolution with padding\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=1, bias=False)\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n",
    "                               padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(planes * 4)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "\n",
    "    def __init__(self, block, layers, num_classes=1000):\n",
    "        self.inplanes = 64\n",
    "        super(ResNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3,\n",
    "                               bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
    "        self.avgpool = nn.AvgPool2d(7)\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        h1 = self.layer1(x)\n",
    "        h2 = self.layer2(h1)\n",
    "        h3 = self.layer3(h2)\n",
    "        h4 = self.layer4(h3)\n",
    "\n",
    "        return [h1, h2, h3, h4]\n",
    "\n",
    "def resnet18(pretrained=False, **kwargs):\n",
    "    \"\"\"Constructs a ResNet-18 model.\n",
    "\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = ResNet(BasicBlock, [2, 2, 2, 2], **kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['resnet18']))\n",
    "    return model\n",
    "\n",
    "def resnet34(pretrained=False, **kwargs):\n",
    "    \"\"\"Constructs a ResNet-34 model.\n",
    "\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = ResNet(BasicBlock, [3, 4, 6, 3], **kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['resnet34']))\n",
    "    return model\n",
    "\n",
    "def resnet50(pretrained=False, **kwargs):\n",
    "    \"\"\"Constructs a ResNet-50 model.\n",
    "\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = ResNet(Bottleneck, [3, 4, 6, 3], **kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['resnet50']))\n",
    "    return model\n",
    "\n",
    "def resnet101(pretrained=False, **kwargs):\n",
    "    \"\"\"Constructs a ResNet-101 model.\n",
    "\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = ResNet(Bottleneck, [3, 4, 23, 3], **kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['resnet101']))\n",
    "    return model\n",
    "\n",
    "def resnet152(pretrained=False, **kwargs):\n",
    "    \"\"\"Constructs a ResNet-152 model.\n",
    "\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = ResNet(Bottleneck, [3, 8, 36, 3], **kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['resnet152']))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DFN:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBnRelu(nn.Module):\n",
    "    def __init__(self, in_planes, out_planes, ksize, stride, pad, dilation=1,\n",
    "                 groups=1, has_bn=True, norm_layer=nn.BatchNorm2d, bn_eps=1e-5,\n",
    "                 has_relu=True, inplace=True, has_bias=False):\n",
    "        super(ConvBnRelu, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_planes, out_planes, kernel_size=ksize,\n",
    "                              stride=stride, padding=pad,\n",
    "                              dilation=dilation, groups=groups, bias=has_bias)\n",
    "        self.has_bn = has_bn\n",
    "        if self.has_bn:\n",
    "            self.bn = norm_layer(out_planes, eps=bn_eps)\n",
    "        self.has_relu = has_relu\n",
    "        if self.has_relu:\n",
    "            self.relu = nn.ReLU(inplace=inplace)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        if self.has_bn:\n",
    "            x = self.bn(x)\n",
    "        if self.has_relu:\n",
    "            x = self.relu(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "class ChannelAttention(nn.Module):\n",
    "    def __init__(self, in_planes, out_planes, reduction):\n",
    "        super(ChannelAttention, self).__init__()\n",
    "        self.channel_attention = SELayer(in_planes, out_planes, reduction)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        fm = torch.cat([x1, x2], 1)\n",
    "        channel_attetion = self.channel_attention(fm)\n",
    "        fm = x1 * channel_attetion + x2\n",
    "\n",
    "        return fm\n",
    "\n",
    "#RRB  fine tuning : actually the method only change the fcn backbone vgg to resnet ,so U need add some residual block.\n",
    "#Is easily understand.\n",
    "class RefineResidual(nn.Module):\n",
    "    def __init__(self, in_planes, out_planes, ksize, has_bias=False,\n",
    "                 has_relu=False, norm_layer=nn.BatchNorm2d, bn_eps=1e-5):\n",
    "        super(RefineResidual, self).__init__()\n",
    "        self.conv_1x1 = nn.Conv2d(in_planes, out_planes, kernel_size=1,\n",
    "                                  stride=1, padding=0, dilation=1,\n",
    "                                  bias=has_bias)\n",
    "        self.cbr = ConvBnRelu(out_planes, out_planes, ksize, 1,\n",
    "                              ksize // 2, has_bias=has_bias,\n",
    "                              norm_layer=norm_layer, bn_eps=bn_eps)\n",
    "        self.conv_refine = nn.Conv2d(out_planes, out_planes, kernel_size=ksize,\n",
    "                                     stride=1, padding=ksize // 2, dilation=1,\n",
    "                                     bias=has_bias)\n",
    "        self.has_relu = has_relu\n",
    "        if self.has_relu:\n",
    "            self.relu = nn.ReLU(inplace=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_1x1(x)\n",
    "        t = self.cbr(x)\n",
    "        t = self.conv_refine(t)\n",
    "        if self.has_relu:\n",
    "            return self.relu(t + x)\n",
    "        return t + x\n",
    "    \n",
    "class SELayer(nn.Module):\n",
    "    def __init__(self, in_planes, out_planes, reduction=16):\n",
    "        super(SELayer, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(in_planes, out_planes // reduction),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(out_planes // reduction, out_planes),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.out_planes = out_planes\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, _, _ = x.size()\n",
    "        y = self.avg_pool(x).view(b, c)\n",
    "        y = self.fc(y).view(b, self.out_planes, 1, 1)\n",
    "        return y\n",
    "\n",
    "class DFN(nn.Module):\n",
    "    def __init__(self, out_planes, criterion, aux_criterion, alpha, norm_layer=nn.BatchNorm2d):\n",
    "        super(DFN, self).__init__()\n",
    "        self.backbone = resnet101(pretrained=True)\n",
    "        #for param in self.backbone.parameters():   # Freeze resnet layers\n",
    "        #    param.requires_grad = False\n",
    "        self.business_layer = []\n",
    "\n",
    "        smooth_inner_channel = 512\n",
    "        self.global_context = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            ConvBnRelu(2048, smooth_inner_channel, 1, 1, 0,\n",
    "                       has_bn=True,\n",
    "                       has_relu=True, has_bias=False, norm_layer=norm_layer)\n",
    "        )\n",
    "        self.business_layer.append(self.global_context)\n",
    "\n",
    "        stage = [2048, 1024, 512, 256]\n",
    "        self.smooth_pre_rrbs = []\n",
    "        self.cabs = []\n",
    "        self.smooth_aft_rrbs = []\n",
    "        self.smooth_heads = []\n",
    "\n",
    "        #every stage we have dfn layer output?\n",
    "        # top to bottom 2048 -> 256\n",
    "        for i, channel in enumerate(stage):\n",
    "            self.smooth_pre_rrbs.append(\n",
    "                RefineResidual(channel, smooth_inner_channel, 3, has_bias=False,\n",
    "                               has_relu=True, norm_layer=norm_layer))\n",
    "            self.cabs.append(\n",
    "                ChannelAttention(smooth_inner_channel * 2,\n",
    "                                 smooth_inner_channel, 1))\n",
    "            self.smooth_aft_rrbs.append(\n",
    "                RefineResidual(smooth_inner_channel, smooth_inner_channel, 3,\n",
    "                               has_bias=False,\n",
    "                               has_relu=True, norm_layer=norm_layer))\n",
    "            self.smooth_heads.append(\n",
    "                DFNHead(smooth_inner_channel, out_planes, scale=2 ** (5 - i),\n",
    "                        norm_layer=norm_layer))\n",
    "\n",
    "        stage.reverse()\n",
    "        border_inner_channel = 5\n",
    "        self.border_pre_rrbs = []\n",
    "        self.border_aft_rrbs = []\n",
    "        self.border_heads = []\n",
    "\n",
    "\n",
    "        for i, channel in enumerate(stage):\n",
    "            self.border_pre_rrbs.append(\n",
    "                RefineResidual(channel, border_inner_channel, 3, has_bias=False,\n",
    "                               has_relu=True, norm_layer=norm_layer))\n",
    "            self.border_aft_rrbs.append(\n",
    "                RefineResidual(border_inner_channel, border_inner_channel, 3,\n",
    "                               has_bias=False,\n",
    "                               has_relu=True, norm_layer=norm_layer))\n",
    "            self.border_heads.append(\n",
    "                DFNHead(border_inner_channel, 1, 4, norm_layer=norm_layer))\n",
    "\n",
    "        self.smooth_pre_rrbs = nn.ModuleList(self.smooth_pre_rrbs)\n",
    "        self.cabs = nn.ModuleList(self.cabs)\n",
    "        self.smooth_aft_rrbs = nn.ModuleList(self.smooth_aft_rrbs)\n",
    "        self.smooth_heads = nn.ModuleList(self.smooth_heads)\n",
    "        self.border_pre_rrbs = nn.ModuleList(self.border_pre_rrbs)\n",
    "        self.border_aft_rrbs = nn.ModuleList(self.border_aft_rrbs)\n",
    "        self.border_heads = nn.ModuleList(self.border_heads)\n",
    "\n",
    "        #smooth model\n",
    "        self.business_layer.append(self.smooth_pre_rrbs)\n",
    "        self.business_layer.append(self.cabs)\n",
    "        self.business_layer.append(self.smooth_aft_rrbs)\n",
    "        self.business_layer.append(self.smooth_heads)\n",
    "\n",
    "        #border_layer model\n",
    "        self.business_layer.append(self.border_pre_rrbs)\n",
    "        self.business_layer.append(self.border_aft_rrbs)\n",
    "        self.business_layer.append(self.border_heads)\n",
    "\n",
    "        self.criterion = criterion\n",
    "        self.aux_criterion = aux_criterion\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def forward(self, data, label=None, aux_label=None):\n",
    "        blocks = self.backbone(data)\n",
    "\n",
    "\n",
    "        '''\n",
    "        >> Block we have 4 conv1 conv2 conv3 conv4\n",
    "        conv1 -> 256 1/4\n",
    "        conv2 -> 512 1/8\n",
    "        conv3 ->1024 1/16\n",
    "        conv4 ->2048 1/32\n",
    "        '''\n",
    "        blocks.reverse()\n",
    "\n",
    "        #understanding the global context meaning:\n",
    "\n",
    "        global_context = self.global_context(blocks[0])\n",
    "        #global: ->(bs,512,1,1)\n",
    "        #equal to squeeze bar\n",
    "        global_context = F.interpolate(global_context,\n",
    "                                       size=blocks[0].size()[2:],\n",
    "                                       mode='bilinear', align_corners=True)\n",
    "        #this part using for smooth model ,this part sometime is important, U must carefully\n",
    "\n",
    "        last_fm = global_context\n",
    "        #last_fm --->(bs,512,1/32,1/32)\n",
    "        pred_out = []\n",
    "\n",
    "        for i, (fm, pre_rrb,\n",
    "                cab, aft_rrb, head) in enumerate(zip(blocks,\n",
    "                                                     self.smooth_pre_rrbs,\n",
    "                                                     self.cabs,\n",
    "                                                     self.smooth_aft_rrbs,\n",
    "                                                     self.smooth_heads)):\n",
    "            #step RRB model\n",
    "            fm = pre_rrb(fm)\n",
    "            #CAB para: low_level,hight_level\n",
    "            fm = cab(fm, last_fm)\n",
    "            fm = aft_rrb(fm)\n",
    "            #RRB model ,next using to next low level , we must up sample\n",
    "\n",
    "            #what is head mean?\n",
    "            pred_out.append(head(fm))\n",
    "            if i != 3:\n",
    "                last_fm = F.interpolate(fm, scale_factor=2, mode='bilinear',\n",
    "                                        align_corners=True)\n",
    "\n",
    "\n",
    "        #every conv# have a predict label (bs,num_label,input_size,input_size)\n",
    "        blocks.reverse()\n",
    "        #change blocks from bottom to top\n",
    "        last_fm = None\n",
    "        boder_out = []\n",
    "        #struct like follow border\n",
    "        '''\n",
    "        conv1 ---RRB------------>head\n",
    "                       |\n",
    "        conv2 ---RRB---+--RRB--->head\n",
    "                            |\n",
    "        conv3 ---RRB---+--RRB--->head\n",
    "                            |\n",
    "        conv4 ---RRB---+--RRB--->head\n",
    "        '''\n",
    "        for i, (fm, pre_rrb,\n",
    "                aft_rrb, head) in enumerate(zip(blocks,\n",
    "                                                self.border_pre_rrbs,\n",
    "                                                self.border_aft_rrbs,\n",
    "                                                self.border_heads)):\n",
    "            fm = pre_rrb(fm)\n",
    "            if last_fm is not None:\n",
    "                fm = F.interpolate(fm, scale_factor=2 ** i, mode='bilinear',\n",
    "                                   align_corners=True)\n",
    "                last_fm = last_fm + fm\n",
    "                last_fm = aft_rrb(last_fm)\n",
    "\n",
    "            else:\n",
    "                last_fm = fm\n",
    "            boder_out.append(head(last_fm))\n",
    "\n",
    "        #if train: loss have 4 layer\n",
    "        #else print the smooth_layer.\n",
    "        #this method is good , we must learning this step\n",
    "        if label is not None and aux_label is not None:\n",
    "            loss0 = self.criterion(pred_out[0], label)\n",
    "            loss1 = self.criterion(pred_out[1], label)\n",
    "            loss2 = self.criterion(pred_out[2], label)\n",
    "            loss3 = self.criterion(pred_out[3], label)\n",
    "\n",
    "            aux_loss0 = self.aux_criterion(boder_out[0], aux_label)\n",
    "            aux_loss1 = self.aux_criterion(boder_out[1], aux_label)\n",
    "            aux_loss2 = self.aux_criterion(boder_out[2], aux_label)\n",
    "            aux_loss3 = self.aux_criterion(boder_out[3], aux_label)\n",
    "\n",
    "            loss = loss0 + loss1 + loss2 + loss3\n",
    "            aux_loss = aux_loss0 + aux_loss1 + aux_loss2 + aux_loss3\n",
    "            return loss + self.alpha * aux_loss, F.log_softmax(pred_out[-1], dim=1)\n",
    "\n",
    "        return F.log_softmax(pred_out[-1], dim=1)\n",
    "\n",
    "\n",
    "class DFNHead(nn.Module):\n",
    "    def __init__(self, in_planes, out_planes, scale, norm_layer=nn.BatchNorm2d):\n",
    "        #remeber the scale means  upsample times\n",
    "        super(DFNHead, self).__init__()\n",
    "        self.rrb = RefineResidual(in_planes, out_planes * 9, 3, has_bias=False,\n",
    "                                  has_relu=False, norm_layer=norm_layer)\n",
    "        self.conv = nn.Conv2d(out_planes * 9, out_planes, kernel_size=1,\n",
    "                              stride=1, padding=0)\n",
    "        self.scale = scale\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.rrb(x)\n",
    "        x = self.conv(x)\n",
    "        x = F.interpolate(x, scale_factor=self.scale, mode='bilinear',\n",
    "                          align_corners=True)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train:**\n",
    "--------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __init_weight(feature, conv_init, norm_layer, bn_eps, bn_momentum,\n",
    "                  **kwargs):\n",
    "    for name, m in feature.named_modules():\n",
    "        if isinstance(m, (nn.Conv2d, nn.Conv3d)):\n",
    "            conv_init(m.weight, **kwargs)\n",
    "        elif isinstance(m, norm_layer):\n",
    "            m.eps = bn_eps\n",
    "            m.momentum = bn_momentum\n",
    "            nn.init.constant_(m.weight, 1)\n",
    "            nn.init.constant_(m.bias, 0)\n",
    "\n",
    "\n",
    "def init_weight(module_list, conv_init, norm_layer, bn_eps, bn_momentum,\n",
    "                **kwargs):\n",
    "    if isinstance(module_list, list):\n",
    "        for feature in module_list:\n",
    "            __init_weight(feature, conv_init, norm_layer, bn_eps, bn_momentum,\n",
    "                          **kwargs)\n",
    "    else:\n",
    "        __init_weight(module_list, conv_init, norm_layer, bn_eps, bn_momentum,\n",
    "                      **kwargs)\n",
    "\n",
    "\n",
    "def group_weight(weight_group, module, norm_layer, lr):\n",
    "    group_decay = []\n",
    "    group_no_decay = []\n",
    "    for m in module.modules():\n",
    "        if isinstance(m, nn.Linear):\n",
    "            group_decay.append(m.weight)\n",
    "            if m.bias is not None:\n",
    "                group_no_decay.append(m.bias)\n",
    "        elif isinstance(m, (nn.Conv2d, nn.Conv3d)):\n",
    "            group_decay.append(m.weight)\n",
    "            if m.bias is not None:\n",
    "                group_no_decay.append(m.bias)\n",
    "        elif isinstance(m, norm_layer) or isinstance(m, nn.GroupNorm):\n",
    "            if m.weight is not None:\n",
    "                group_no_decay.append(m.weight)\n",
    "            if m.bias is not None:\n",
    "                group_no_decay.append(m.bias)\n",
    "\n",
    "    assert len(list(module.parameters())) == len(group_decay) + len(\n",
    "        group_no_decay)\n",
    "    weight_group.append(dict(params=group_decay, lr=lr))\n",
    "    weight_group.append(dict(params=group_no_decay, weight_decay=.0, lr=lr))\n",
    "    return weight_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABCMeta, abstractmethod\n",
    "\n",
    "\n",
    "class BaseLR():\n",
    "    __metaclass__ = ABCMeta\n",
    "\n",
    "    @abstractmethod\n",
    "    def get_lr(self, cur_iter): pass\n",
    "\n",
    "    \n",
    "class PolyLR(BaseLR):\n",
    "    def __init__(self, start_lr, lr_power, total_iters):\n",
    "        self.start_lr = start_lr\n",
    "        self.lr_power = lr_power\n",
    "        self.total_iters = total_iters + 0.0\n",
    "\n",
    "    def get_lr(self, cur_iter):\n",
    "        return self.start_lr * (\n",
    "                (1 - float(cur_iter) / self.total_iters) ** self.lr_power)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "params_train = {'batch_size': 4,\n",
    "          'shuffle': True,\n",
    "          'num_workers': 6}\n",
    "\n",
    "params_val = {'batch_size': 4,\n",
    "          'shuffle': False,\n",
    "          'num_workers': 6}\n",
    "\n",
    "max_epochs = 80\n",
    "\n",
    "train, test = train_test_split(train_df2, test_size=0.15, random_state=42, stratify=train_df2['class'])\n",
    "\n",
    "train_dataset = SteelDataset(train, 'ImageId', ['EP1', 'EP2', 'EP3', 'EP4'], train_path)\n",
    "training_generator = DataLoader(train_dataset, **params_train)\n",
    "\n",
    "val_dataset = SteelDataset(test, 'ImageId', ['EP1', 'EP2', 'EP3', 'EP4'], train_path)\n",
    "validation_generator = DataLoader(val_dataset, **params_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cudnn.benchmark = True\n",
    "\n",
    "# config network and criterion\n",
    "criterion = nn.CrossEntropyLoss(reduction='mean',\n",
    "                                ignore_index=255)\n",
    "aux_criterion = SigmoidFocalLoss(ignore_label=255, gamma=2.0, alpha=0.1)\n",
    "\n",
    "model = DFN(5, criterion=criterion,\n",
    "            aux_criterion=aux_criterion, alpha=0.25,\n",
    "            norm_layer=nn.BatchNorm2d)\n",
    "init_weight(model.business_layer, nn.init.kaiming_normal_,\n",
    "            nn.BatchNorm2d, 1e-5, 0.1,\n",
    "            mode='fan_in', nonlinearity='relu')\n",
    "\n",
    "# group weight and config optimizer\n",
    "base_lr = 8e-4\n",
    "\n",
    "params_list = []\n",
    "params_list = group_weight(params_list, model.backbone,\n",
    "                           nn.BatchNorm2d, base_lr)\n",
    "for module in model.business_layer:\n",
    "    params_list = group_weight(params_list, module, nn.BatchNorm2d,\n",
    "                               base_lr * 10)\n",
    "\n",
    "optimizer = torch.optim.SGD(params_list,\n",
    "                            lr=base_lr,\n",
    "                            momentum=0.9,\n",
    "                            weight_decay=1e-4)\n",
    "\n",
    "# config lr policy\n",
    "total_iteration = max_epochs * len(training_generator)\n",
    "lr_policy = PolyLR(base_lr, 0.9, total_iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(state, is_best, filename='./model5.pth'):\n",
    "    # taken from https://blog.floydhub.com/checkpointing-tutorial-for-tensorflow-keras-and-pytorch/\n",
    "    \"\"\"Save checkpoint if a new best is achieved\"\"\"\n",
    "    if is_best:\n",
    "        print (\"=> Saving a new best\")\n",
    "        torch.save(state, filename)  # save checkpoint\n",
    "    else:\n",
    "        print (\"=> Validation Accuracy did not improve\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique(tensor1d):\n",
    "    t, idx = np.unique(tensor1d.numpy(), return_inverse=True)\n",
    "    return torch.from_numpy(t), torch.from_numpy(idx) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ckpt_path = \"../input/severstal-dfn/model.pth\"\n",
    "#state = torch.load(ckpt_path, map_location=lambda storage, loc: storage)\n",
    "#model.load_state_dict(state[\"state_dict\"])\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensorboard\n",
    "writer = SummaryWriter()\n",
    "\n",
    "best_loss_set = False\n",
    "model.train()\n",
    "for epoch in range(max_epochs):\n",
    "    running_loss_train = 0\n",
    "    running_dice_coeff_train = 0\n",
    "    running_iou_train = 0\n",
    "    #start = time.strftime(\"%H:%M:%S\")\n",
    "    \n",
    "    for idx, minibatch in enumerate(training_generator):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        imgs = minibatch['image'].float()\n",
    "        gts = minibatch['masks'].long()\n",
    "        cgts = minibatch['cgt'].float()\n",
    "\n",
    "        imgs = imgs.cuda()\n",
    "        gts = gts.cuda()\n",
    "        cgts = cgts.cuda()\n",
    "        \n",
    "        #print(unique(imgs.cpu().detach()))\n",
    "        #print(unique(gts.cpu().detach()))\n",
    "        #print(unique(cgts.cpu().detach()))\n",
    "\n",
    "\n",
    "        loss, outputs = model(imgs, gts, cgts)\n",
    "\n",
    "        #print(unique(outputs.cpu().detach()))\n",
    "        #y = gts.cpu().detach()\n",
    "        \n",
    "        # Print metrics\n",
    "        running_loss_train += loss.item()\n",
    "        _, dice_coeff = dice(torch.exp(outputs.double().cpu().detach()).int(), gts.double().cpu().detach())\n",
    "        running_dice_coeff_train += dice_coeff\n",
    "        #iou = IoU(outputs.double(), gts.double())\n",
    "        #running_iou_train += iou\n",
    "\n",
    "        current_idx = epoch * len(training_generator) + idx\n",
    "        lr = lr_policy.get_lr(current_idx)\n",
    "\n",
    "        optimizer.param_groups[0]['lr'] = lr\n",
    "        optimizer.param_groups[1]['lr'] = lr\n",
    "        for i in range(2, len(optimizer.param_groups)):\n",
    "            optimizer.param_groups[i]['lr'] = lr * 10\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        print(\"Batch {}/{}, Loss: {:.5f}, Dice-Coeff: {:.5f}\".format(idx+1, len(training_generator),loss,dice_coeff), end='\\r')\n",
    "        sys.stdout.flush()    \n",
    "\n",
    "        \n",
    "    with torch.set_grad_enabled(False):\n",
    "        running_loss_val = 0\n",
    "        running_dice_coeff_val = 0\n",
    "        running_iou_val = 0\n",
    "        running_class_dice_coeff_val = np.zeros(5)\n",
    "        for idx, minibatch in enumerate(validation_generator):\n",
    "            imgs = minibatch['image'].float()\n",
    "            gts = minibatch['masks'].long()\n",
    "            cgts = minibatch['cgt'].float()\n",
    "\n",
    "            imgs = imgs.cuda(non_blocking=True)\n",
    "            gts = gts.cuda(non_blocking=True)\n",
    "            cgts = cgts.cuda(non_blocking=True)\n",
    "\n",
    "            loss, outputs = model(imgs, gts, cgts)\n",
    "\n",
    "            running_loss_val += loss.item()\n",
    "            class_dice_coeff, dice_coeff = dice(torch.exp(outputs.double().cpu()).int(), gts.double().cpu())\n",
    "            running_dice_coeff_val += dice_coeff\n",
    "            running_class_dice_coeff_val = np.add(running_class_dice_coeff_val, class_dice_coeff)\n",
    "            \n",
    "            #iou = IoU(outputs.double(), gts.double())\n",
    "            #running_iou_val += iou\n",
    "        loss = running_loss_train/len(training_generator)\n",
    "        val_loss = running_loss_val/len(validation_generator)\n",
    "        dice_coeff = running_dice_coeff_train/len(training_generator)\n",
    "        val_dice_coeff = running_dice_coeff_val/len(validation_generator)\n",
    "        running_class_dice_coeff_val /= len(validation_generator)\n",
    "        \n",
    "                    \n",
    "        writer.add_scalar('Loss', loss, epoch)\n",
    "        writer.add_scalar('Val-Loss', val_loss, epoch)\n",
    "        writer.add_scalar('Dice-Coeff', dice_coeff, epoch)\n",
    "        writer.add_scalar('Val-Dice-Coeff', val_dice_coeff, epoch)\n",
    "        writer.add_scalar('Val-Class0-Dice-Coeff', running_class_dice_coeff_val[0], epoch)\n",
    "        writer.add_scalar('Val-Class1-Dice-Coeff', running_class_dice_coeff_val[1], epoch)\n",
    "        writer.add_scalar('Val-Class2-Dice-Coeff', running_class_dice_coeff_val[2], epoch)\n",
    "        writer.add_scalar('Val-Class3-Dice-Coeff', running_class_dice_coeff_val[3], epoch)\n",
    "        writer.add_scalar('Val-Class4-Dice-Coeff', running_class_dice_coeff_val[4], epoch)\n",
    "        #iou = running_iou_train/len(training_generator)\n",
    "        #val_iou = running_iou_val/len(validation_generator)\n",
    "        print(\"Epoch {}/{}, Loss: {:.3f}, Val-Loss: {:.3f}, Dice-Coeff: {:.3f}, Val-Dice-Coeff: {:.3f}, Val-Class-Dice-Coeff: {}\".format(epoch+1, max_epochs, loss, val_loss, dice_coeff, val_dice_coeff, running_class_dice_coeff_val))\n",
    "\n",
    "        # Save checkpoint if is a new best\n",
    "        if best_loss_set:\n",
    "            is_best = bool(best_loss < val_dice_coeff)\n",
    "            best_loss = max(val_dice_coeff, best_loss)\n",
    "            save_checkpoint({\n",
    "                'epoch': epoch + 1,\n",
    "                'state_dict': model.state_dict(),\n",
    "                'best_loss': best_loss\n",
    "            }, is_best)\n",
    "        else:\n",
    "            best_loss = val_dice_coeff\n",
    "            save_checkpoint({\n",
    "                'epoch': epoch + 1,\n",
    "                'state_dict': model.state_dict(),\n",
    "                'best_loss': best_loss\n",
    "            }, True)\n",
    "            best_loss_set = True\n",
    "\n",
    "        # Reduce LR on Plateau\n",
    "        #scheduler.step(loss)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# freeze resnet layers -\n",
    "# changed SGD to Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_path = \"./model.pth\"\n",
    "state = torch.load(ckpt_path, map_location=lambda storage, loc: storage)\n",
    "model.load_state_dict(state[\"state_dict\"])\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "with torch.set_grad_enabled(False):\n",
    "    for idx, minibatch in enumerate(validation_generator):\n",
    "        imgs = minibatch['image'].float()#\n",
    "\n",
    "        imgs = imgs.cuda(non_blocking=True)#\n",
    "\n",
    "        outputs = model(imgs)\n",
    "        masks = torch.exp(outputs.double().cpu()).int()\n",
    "        for mask in masks:\n",
    "            preds.append(build_rles(mask.permute(1,2,0).numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(200,400,5):\n",
    "    inc = i\n",
    "    fig, axs = plt.subplots(15, figsize=(25, 25))\n",
    "    for i in range(0,15,3):\n",
    "        masks = build_masks(preds[i+inc], (128, 800))\n",
    "        axs[i].imshow(val_dataset[i+inc]['image'].permute(1, 2, 0)[:,:,0], cmap='gray')\n",
    "        axs[i].axis('off')\n",
    "        axs[i+1].imshow(masks)\n",
    "        axs[i+1].axis('off')\n",
    "        axs[i+2].imshow(val_dataset[i+inc]['masks'])\n",
    "        axs[i+2].axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Threshold:**\n",
    "------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def post_process(mask_in, min_size=3500):\n",
    "#    '''Post processing of each predicted mask, components with lesser number of pixels\n",
    "#    than `min_size` are ignored'''\n",
    "#    mask = cv2.threshold(mask_in, 0.5, 1, cv2.THRESH_BINARY)[1]\n",
    "#    num_component, component = cv2.connectedComponents(mask.astype(np.uint8))\n",
    "#    predictions = np.zeros((256, 1600), np.float32)\n",
    "#    num = 0\n",
    "#    for c in range(1, num_component):\n",
    "#        p = (component == c)\n",
    "#        if p.sum() > min_size:\n",
    "#            predictions[p] = 1\n",
    "#            num += 1\n",
    "#    mask_out = np.multiply(mask_in, predictions)\n",
    "#    #print(mask_out.shape)\n",
    "#    return mask_out, num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preds = []\n",
    "#with torch.set_grad_enabled(False):\n",
    "#    dice_coeff_val = []\n",
    "#    running_dice_coeff_val = np.zeros(11)\n",
    "#    for idx, minibatch in enumerate(tqdm(validation_generator)):\n",
    "#        imgs = minibatch['image'].float()\n",
    "#        gts = minibatch['masks'].int()#\n",
    "\n",
    "#        imgs = imgs.cuda(non_blocking=True)\n",
    "#\n",
    "#        outputs = model(imgs)\n",
    "#        masks = torch.exp(outputs.double().cpu())\n",
    "#        l = 0\n",
    "#        for k in range(0,5001,500):\n",
    "#            for i, masks_ in enumerate(masks):\n",
    "#                tmp_masks = []\n",
    "#                for j, mask in enumerate(masks_):\n",
    "#                    pred, num = post_process(mask.numpy(), k)\n",
    "#                    tmp_masks.append(pred)\n",
    "#                masks[i] = torch.Tensor(tmp_masks).double()\n",
    "#                #preds.append(build_rles(pred.permute(1,2,0).numpy()))#\n",
    "\n",
    "#            dice_coeff = dice(masks.int(), gts)\n",
    "#            running_dice_coeff_val[l] += dice_coeff\n",
    "#            l += 1\n",
    "#    dice_coeff_val = [running_dice_coeff_val[o]/len(validation_generator) for o in range(len(running_dice_coeff_val))]\n",
    "#    print(dice_coeff_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.plot(list(range(0,5001,500)), dice_coeff_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import FileLink\n",
    "FileLink('./model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
